{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff71e11-e80c-43d5-a7fb-f014d3e2488f",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue; font-weight:bold\"> GLM üîçüìäüìà</span>\n",
    "\n",
    "igual que el modelo final que obtuve en R para failures\n",
    "\n",
    "no normalizo (comentado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60aef6f5-a1b8-4e77-a4b1-7b1be864bb0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1845,2) (1845,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60443/1548732225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                        \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv_normalized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                        family=sm.families.Gamma(link=sm.families.links.log()))\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Show fitted model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, maxiter, method, tol, scale, cov_type, cov_kwds, use_t, full_output, disp, max_start_irls, **kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eim'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0mcov_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nonrobust'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m             return self._fit_irls(start_params=start_params, maxiter=maxiter,\n\u001b[0m\u001b[1;32m   1076\u001b[0m                                   \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                                   cov_kwds=cov_kwds, use_t=use_t, **kwargs)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py\u001b[0m in \u001b[0;36m_fit_irls\u001b[0;34m(self, start_params, maxiter, tol, scale, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0mlin_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwlsexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset_exposure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m         dev = self.family.deviance(self.endog, mu, self.var_weights,\n\u001b[1;32m   1190\u001b[0m                                    self.freq_weights, self.scale)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py\u001b[0m in \u001b[0;36mestimate_scale\u001b[0;34m(self, mu)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimate_x2_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaletype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py\u001b[0m in \u001b[0;36m_estimate_x2_scale\u001b[0;34m(self, mu)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_estimate_x2_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m         \u001b[0mresid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresid\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_resid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1845,2) (1845,) "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the input data\n",
    "csv = pd.read_csv(\"../1_datasets/simcomms/processed_data_simcomms_0.5_full_jun16\", index_col=\"sample\")\n",
    "csv = csv.drop(['transfer', 'reached_fixation_at',\n",
    "               'filename', 'initial_size', 'final_size',\n",
    "               'filt_even', 'filt_shannon', 'gini'\n",
    "# 'raw_even', 'richness', 'distrib'\n",
    "               ], axis=1)\n",
    "\n",
    "csv[\"logdilfactor\"] = np.log(csv.dilfactor)\n",
    "csv[\"failure\"] = pd.isna(csv.success)\n",
    "\n",
    "csv = csv.dropna()\n",
    "csv = csv.replace(to_replace=\"1.00E+06\", value=100000)\n",
    "csv.distrib = [1 if i==\"uniform\" else 0 for i in csv.distrib]\n",
    "\n",
    "# Filter by dilution factor (!!!!)\n",
    "csv = csv[csv.dilfactor < 0.01]\n",
    "csv = csv[csv.dilfactor > 0.00025]\n",
    "\n",
    "# out\n",
    "prefix = \"GLM/\"\n",
    "\n",
    "\n",
    "\n",
    "# Normalize the variables in X\n",
    "y = csv.failure.to_list()\n",
    "variable_names = [\"size\", \"raw_even\", \"logdilfactor\"]\n",
    "scaler = MinMaxScaler()\n",
    "csv_normalized = pd.DataFrame(scaler.fit_transform(csv[variable_names]), columns = variable_names)\n",
    "csv_normalized[\"failure\"] = y\n",
    "\n",
    "# Fit the GLM with a negative exponential distribution\n",
    "model = sm.formula.glm(formula = \"failure ~ size:logdilfactor +  raw_even  + size  + logdilfactor\",\n",
    "                       data=csv_normalized,\n",
    "               ## cambiar!!!        family=sm.families.Gamma(link=sm.families.links.log()))\n",
    "result = model.fit()\n",
    "\n",
    "# Show fitted model\n",
    "print(result.summary())\n",
    "coefficients = result.params\n",
    "print(coefficients)\n",
    "\n",
    "# Regression formula\n",
    "regression_formula = \"y = \"\n",
    "for i in range(len(variable_names)):\n",
    "    coefficient = coefficients[i]\n",
    "    variable_name = variable_names[i]\n",
    "    regression_formula += f\"({coefficient:.4f} * {variable_name}) + \"\n",
    "\n",
    "# Print the regression formula\n",
    "print(regression_formula[0:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914456f5-bb34-4f3f-848f-c4b80909d9ba",
   "metadata": {},
   "source": [
    "- Really good pseudo R-squ. (CS):            \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5eed5-f671-459c-8906-3bbce9b6577e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coefficient Plot\n",
    "def plot_coefficients(result):\n",
    "    coef_df = result.conf_int()\n",
    "    coef_df['Coefficient'] = result.params\n",
    "    coef_df.columns = ['Lower CI', 'Upper CI', 'Coefficient']\n",
    "    coef_df.dropna(inplace=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    coef_df['Coefficient'].plot(kind='barh', ax=ax)\n",
    "    ax.errorbar(x=coef_df['Coefficient'], y=coef_df.index, xerr=(coef_df['Coefficient'] - coef_df['Lower CI'], coef_df['Upper CI'] - coef_df['Coefficient']),\n",
    "                fmt='o', color='black', alpha=0.7)\n",
    "    ax.set_xlabel('Coefficient')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.set_title('Coefficient Plot')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_coefficients(result)\n",
    "\n",
    "# Variable Importance Plot (importance==absolute value of coefficients\n",
    "def plot_var_importance_plot(result, variable_names):\n",
    "    importance_df = pd.DataFrame({'Variable': [\"const\"] + variable_names, # don't include constant\n",
    "                                  'Importance': list(np.abs(result.params))})\n",
    "    importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(7, 6), dpi=80)\n",
    "\n",
    "    # Create a bar plot of the feature importances\n",
    "    plt.bar(range(len(variable_names)+1), importance_df.Importance)\n",
    "\n",
    "    # Add axis labels and a title to the plot\n",
    "    plt.xticks(range(len(variable_names)+1), [\"const\"] + variable_names, rotation=90)\n",
    "    plt.ylabel('Feature Importance')\n",
    "    plt.title('Feature Importance Plot')\n",
    "\n",
    "    # Add axis labels and a title to the plot\n",
    "    plt.xticks(range(len(variable_names)+1), [\"const\"] + variable_names, rotation=90)\n",
    "    plt.ylabel('Feature Importance')\n",
    "    plt.title('Feature Importance Plot')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(prefix + \"feature_importance.png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_var_importance_plot(result, list(result.params.index[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8afcb3-222e-4ab0-88cf-9337008e055c",
   "metadata": {},
   "source": [
    "### <span style=\"color:darkblue; font-weight:bold\"> more plots üîçüìäüìà</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607db755-3580-4d3f-a399-ab544a6dc6f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "# Another simple plot is to put all y (real) values in a set order\n",
    "csv2 = csv#[csv[\"dilfactor\"]==0.04]\n",
    "\n",
    "for n, i in enumerate([\"dilfactor\", \"raw_shannon\", \"distrib\", \"richness\", \"size\", \"raw_even\"]):\n",
    "    name = [\"Dilution factor\", \"Shannon diversity\", \"Abundance distribution\", \"Richness\", \"Total community size\", \"Evenness\", \"Gini index\"][n]\n",
    "    \n",
    "    cmap = None\n",
    "    mynorm = None\n",
    "    ## Logarithmic color scale for these\n",
    "    if i in [\"richness\", \"dilfactor\"]:\n",
    "        mynorm = colors.LogNorm()\n",
    "    ## Not a gradient needed for these\n",
    "    if i in [\"distrib\", \"size\"]:\n",
    "        cmap = colors.ListedColormap([\"#541352FF\", \"yellow\"])  # Binary colormap (viridis)\n",
    "        bounds = [np.unique(csv2[i]).min(), np.unique(csv2[i]).max()]  # Boundaries for colormap\n",
    "        \n",
    "        plt.figure(figsize=(10, 8), dpi=80)\n",
    "        plt.scatter(range(csv2.shape[0]),\n",
    "                    csv2.failure,\n",
    "                    c=csv2[i],\n",
    "                    cmap=cmap,\n",
    "                    norm=None,\n",
    "                    facecolors=\"none\",\n",
    "                    alpha=0.5)\n",
    "        plt.title(name)\n",
    "        cbar = plt.colorbar(ticks=bounds)\n",
    "        cbar.ax.set_yticklabels([\"Log-normal\", \"Uniform\"])\n",
    "    else:\n",
    "        plt.figure(figsize=(10, 8), dpi=80)\n",
    "        plt.scatter(range(csv2.shape[0]),\n",
    "                    csv2.failure,\n",
    "                    c=csv2[i],\n",
    "                    norm=mynorm,\n",
    "                    facecolors=\"none\",\n",
    "                    alpha=0.5)\n",
    "        plt.title(name)\n",
    "        plt.colorbar()\n",
    "    \n",
    "\n",
    "    plt.title(name)\n",
    "    plt.ylabel(\"Dilution-transfer cycle\")\n",
    "    plt.xticks([])\n",
    "    plt.xlabel(\"‚Üê Communities ‚Üí\")\n",
    "    plt.savefig(prefix + i + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
